<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Scraping | .Mapless]]></title>
  <link href="http://dfenjves.github.io/blog/categories/scraping/atom.xml" rel="self"/>
  <link href="http://dfenjves.github.io/"/>
  <updated>2014-08-29T15:57:28-04:00</updated>
  <id>http://dfenjves.github.io/</id>
  <author>
    <name><![CDATA[Daniel Fenjves]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Notes From a Weekend of Hacking]]></title>
    <link href="http://dfenjves.github.io/blog/2014/04/18/notes-from-a-weekend-of-hacking/"/>
    <updated>2014-04-18T13:53:45-04:00</updated>
    <id>http://dfenjves.github.io/blog/2014/04/18/notes-from-a-weekend-of-hacking</id>
    <content type="html"><![CDATA[<p>I’m piecing together a little Sinatra app that scrapes Yelp and displays schedule data for the many museums in New York. It’s an interesting exercise and has been pretty challenging so far. It’s not finished yet, but here are a few thoughts and lessons from my work:</p>

<p>1) rspec &ndash; I had a lot of time getting rspec working, but I found that checking all of the dependencies and essentially testing each piece of the process was the best way to troubleshoot the bugs I was getting. Once I had spec working, I actually got into the groove of writing tests and then immediately solving those tests in the models I was building. The best way to go about it is to write the tests precisely and with a narrow enough scope that they don’t seem totally overwhelming when it comes to solving them. Also .to be is not the same as .to eq. ().to be() looks for an exact object match, as opposed to eq, which looks for the contents of the object to be the same.</p>

<!-- more -->


<p>2)There’s an issue with the Time object in ruby. Sometimes you need times without dates &ndash; as is the case with a schedule: The MoMA is open from 8:30am to 5:30pm on Wednesdays &ndash; but it seems that the Time and DateTime classes require a date as well as a time. There’s a nice little discussion to read here: <a href="https://www.ruby-forum.com/topic/215970.">https://www.ruby-forum.com/topic/215970.</a> Here’s what I did to get around this &ndash; not sure if it’s ok or will come back to bite me so any thoughts are very welcome: I assigned an arbitrary date (2000,1,1) to serve as a placeholder. So I have a string “10:30 am &ndash; 5:00pm”. How do I get this into a Time format?</p>

<p><code>ruby
opening_string = week_hash[day].split(" - ")[0]
t = Time.new(2000,1,1,(opening_string[0..1].to_i),(opening_string[3..4].to_i))
@open = t.strftime("%H:%M")
closing_string = week_hash[day].split(" - ")[1]
p = Time.new(2000,1,1,(closing_string[0..1].to_i+12),(closing_string[3..4].to_i))
@close = p.strftime("%H:%M”)
</code></p>

<p>It’s not pretty, but it seems to do the trick. If there’s a better way to do this, I’d like to know it.</p>

<p>3) It was interesting to think about the structure of the project. I built one model whose purpose it is to scrape Yelp using nokogiri, and another model to build a museum instance using the data that was pulled from yelp. I had trouble with redundancy as there were methods in the two models that seemed to be doing the same thing. My initialize method for a Museum.new is a good example of this:</p>

<p>```ruby</p>

<pre><code> def initialize(yelp_object)
      @yelp_object = yelp_object
      @name = yelp_object.name
      @schedule = yelp_object.schedule
      set_week_hash
      set_times(:wednesday)
 end
</code></pre>

<p>```
Essentially the name and schedule instance variables are just pulling from the yelp-object methods with the same names. Seems weird.</p>

<p>Anyway, I’m rambling &ndash; would love some feedback if anyone can provide!
D</p>

<p>The code so far: <a href="https://github.com/dfenjves/is-it-open">https://github.com/dfenjves/is-it-open</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How Legal Is Web Scraping?"]]></title>
    <link href="http://dfenjves.github.io/blog/2014/04/18/how-legal-is-web-scraping/"/>
    <updated>2014-04-18T13:53:13-04:00</updated>
    <id>http://dfenjves.github.io/blog/2014/04/18/how-legal-is-web-scraping</id>
    <content type="html"><![CDATA[<p>I’ve recently learned how to perform basic web scraping using nothing but Nokogiri, Open-Uri, Ruby, a paperclip, and the internet. It’s an awesome feeling &ndash; to be able to MacGyver your way deep in to the code of a massive website and pull out exactly what you need, throw it into a database, and then manipulate that data to your heart’s content. It’s like I’ve discovered that I have a secret superpower, and am only beginning to see what I can do with it.</p>

<p style="text-align:center;"> <img src="/images/macgyver.jpg" alt="MacGyver" /></p>

<p style="text-align:center;"> <em>How I felt when I scraped my first website</em></p>

<p>But, as the cliched superhero movie line goes: Son, with great power comes great responsibility. Cue John Williams music.</p>

<!-- more -->


<p>What is that responsibility when it comes to web scraping, exactly? Well, web scraping lives in a grey area of internet law. It’s a weird twilight zone of legality, where people operate in an uncertain haze- unsure of whether scraping is within or beyond the bounds of the law. Let’s examine this grey area in further depth.</p>

<p>But first, a primer on scraping. Imagine being able to set up a system on your computer that goes through every link on Amazon.com and finds the name of every book in their catalog, it’s price, and it’s release date. Or building a program that is able to go through your Facebook friends and pull their publicly available information in to your computer. Or grabbing prices on Craigslist for all 400 apartment listings within a mile of your house in New York without having to manually click on each link. That is web scraping in a nutshell. Using a variety of programs, a scraper is a computer program developed to copy publicly available information from a website.</p>

<p>Notice that I said <em>publicly available</em>. Obviously scraping someone’s online bank accounts will get you thrown in jail faster than you can say <em>identity theft</em>. It’s the stuff that’s out there for everyone to see that makes for an interesting exploration. Is information in the yellow pages subject to copyright protection? Or listings on craigslist? What about the titles and urls of YouTube videos? Check out these interesting legal cases and see what conclusion you can come to:</p>

<p><strong>Feist Publications, Inc., v. Rural Telephone Service Co.</strong>, <em>499 U.S. 340 (1991),[1] is a decision by the Supreme Court of the United States establishing that information alone without a minimum of original creativity cannot be protected by copyright. In the case appealed, Feist had copied information from Rural’s telephone listings to include in its own, after Rural had refused to license the information. Rural sued for copyright infringement. The Court ruled that information contained in Rural’s phone directory was not copyrightable and that therefore no infringement existed.</em></p>

<p>Ok, so pulling information from something like a telephone directory isn’t copyright infringement, because they’re facts and not an artistic creation. Cool. But what is the equivalent of that online? Craigslist? Yellowpages.com (ha.)?</p>

<p><strong>American Airlines vs. Farechase</strong>
 <em>AA successfully obtained an injunction from a Texas trial court, stopping FareChase from selling software that enables users to compare online fares if it also searches AA’s website. The airline argued that FareChase’s websearch software trespassed on AA’s servers when it collected the publicly available data. FareChase filed an appeal in March 2003. By June, FareChase and AA agreed to settle and the appeal was dropped.[9]</em></p>

<p>Woah, woah, woah. Farechase was blocked from scraping AA’s site, despite the data begin publicly available and factual (although sometimes airline prices can definitely seem like fiction) ? That seems to contradict the Feist case, doesn’t it? If you dig a little deeper in to the decision though, you’ll note that American claimed their ‘web fares’ were restricted to only their site (as opposed to the fares disseminated to other websites &ndash; think Orbitz or Kayak). Since they were restricted to their own site, perhaps the scrape wasn’t pulling <em>publicly available</em> information, per se. Although that seems like something of a leap, if I may say so.</p>

<p><strong>eBay v. Bidder’s Edge</strong>, <em>100 F.Supp.2d 1058 (N.D. Cal. 2000), was a leading case applying the trespass to chattels doctrine to online activities. In 2000, eBay, an online auction company, successfully used the ‘trespass to chattels’ theory to obtain a preliminary injunction preventing Bidder’s Edge, an auction data aggregator, from using a ‘crawler' to gather data from eBay&rsquo;s website.[1] The opinion was a leading case applying ‘trespass to chattels’ to online activities, although its analysis has been criticized in more recent jurisprudence.</em></p>

<p>So web crawling differs from web scraping in several ways, but the idea is the same &ndash; pulling data out of  a website. The eBay case is a big one for internet law &ndash; Bidder’s Edge was enjoined from crawling eBay for auction data on the grounds of ‘trespass to chattel’ &ndash; <em>a tort whereby the infringing party has intentionally (or, in Australia, negligently) interfered with another person’s lawful possession of a chattel (movable personal property).</em></p>

<p>Another additional consideration: While scraping may or may not be of dubious legality, websites set their own terms of service and can ban you from accessing them if you engage in practices that violate these terms. For example, from the YouTube terms:</p>

<p><em>You agree not to use or launch any automated system, including without limitation, “robots,” “spiders,” or “offline readers,” that accesses the Service in a manner that sends more request messages to the YouTube servers in a given period of time than a human can reasonably produce in the same period by using a conventional on-line web browser.</em></p>

<p>I guess the conclusion to draw here is that while the legality of scraping is pretty unclear, unless you’re willing to take on a company in court, err on the side of using an API or other acceptable method of accessing their data. Or don’t, you rebel. It’s up to you.</p>

<p>(Additional interesting reading from the New Yorker <a href="http://www.newyorker.com/online/blogs/elements/2014/02/when-programmers-scrape-by.html">here</a>)</p>
]]></content>
  </entry>
  
</feed>
